{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8468ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7ed518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputEmbeddingLayer(nn.Module):\n",
    "    def __init__(self,vocab_size,emb_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.emb_dim=emb_dim\n",
    "        self.embedding_layer=nn.Embedding(self.vocab_size,self.emb_dim,dtype=torch.float16)\n",
    "    def forward(self,x):\n",
    "        embeddings=self.embedding_layer(x)\n",
    "        return embeddings*math.sqrt(self.emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f724db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer=inputEmbeddingLayer(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4c0416b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0947, -4.6719, -2.4785,  1.9209, -0.7163,  1.7715],\n",
       "         [ 1.7021, -1.1729,  1.3672, -0.1871, -0.7930, -4.7969],\n",
       "         [ 2.8633,  2.8418, -1.0898, -1.4854,  1.1201, -0.5195]],\n",
       "\n",
       "        [[ 0.7690, -1.3906, -4.7969,  5.4727, -2.4434, -1.7764],\n",
       "         [-0.1520, -4.5078, -0.4961, -1.3623,  0.7603, -1.7178],\n",
       "         [ 0.7769,  0.7603,  2.0234, -1.7139,  2.1465, -3.6973]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input=torch.tensor([[1,2,3],[4,5,6]])\n",
    "input_embeddings=embedding_layer(test_input)\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "38abc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class positionalEncodingLayer(nn.Module):\n",
    "    def __init__(self,max_seq_len,emb_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.max_seq_len=max_seq_len\n",
    "        self.emb_dim=emb_dim\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        static_positional_info=torch.zeros((self.max_seq_len,self.emb_dim),dtype=torch.float16)\n",
    "        positions=torch.arange(0,max_seq_len,dtype=torch.float16).reshape(max_seq_len,-1)\n",
    "        indices_for_denominator=torch.arange(0,emb_dim,2,dtype=torch.float16) ### 2i\n",
    "        denominators=torch.exp((-2*indices_for_denominator*math.log(1e4))/emb_dim)\n",
    "        static_positional_info[:,0::2]=torch.sin(positions*denominators)\n",
    "        static_positional_info[:,1::2]=torch.cos(positions*denominators)\n",
    "        self.register_buffer('static_positional_info',static_positional_info)\n",
    "    def forward(self,x):\n",
    "        position_encoded_embedding=x+self.static_positional_info[:x.shape[1],:]\n",
    "        dropped_embeddings=self.dropout(position_encoded_embedding)\n",
    "        return dropped_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c3326665",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding_layer=positionalEncodingLayer(3,6,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "83f95915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.7930, -0.0000, -3.4707, -0.1786,  0.0000, -0.6113],\n",
       "         [ 1.5234,  0.0000, -0.0000,  4.4062,  3.3047, -2.2070],\n",
       "         [ 7.6914, -2.3262, -2.8711, -4.4297,  1.3916,  3.4570]],\n",
       "\n",
       "        [[ 0.0000, -0.3279,  0.0000,  0.0000,  4.3633,  2.4062],\n",
       "         [ 2.5273,  0.0000, -1.1494,  0.0000, -0.0000,  2.8711],\n",
       "         [-2.0020, -0.0000,  0.0000, -0.2791, -0.0000, -4.6094]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_encoded_embedding=positional_encoding_layer(input_embeddings)\n",
    "position_encoded_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "01dc91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,dropout):\n",
    "        super().__init__()\n",
    "        assert emb_dim%n_heads==0 ### checking if multi head splitting is possible.\n",
    "        self.w_q=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_k=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_v=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_o=nn.Linear(emb_dim,emb_dim,dtype=torch.float16) ### multi-head-projection-layer\n",
    "        self.emb_dim=emb_dim\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.single_head_dim=self.emb_dim//n_heads\n",
    "        self.n_heads=n_heads\n",
    "\n",
    "    @staticmethod\n",
    "    def contextual_embedding(m_q,m_k,m_v,per_head_emb_dim,mask):\n",
    "        ### return contexual embedding and attention scores\n",
    "        attention_scores=m_q@m_k.transpose(2,3)/math.sqrt(per_head_emb_dim)\n",
    "        ##batch,head,seq,dim @ batch,head,dim,seq==batch,head,seq,seq\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask,value=float('-inf'))\n",
    "        normalized_attention_scores=torch.softmax(attention_scores,dim=-1)\n",
    "        ### batch,head,seq,seq @ batch,head,seq,dim=batch,head,seq,dim\n",
    "        contexual_embeddings=normalized_attention_scores@m_v\n",
    "        return normalized_attention_scores,contexual_embeddings\n",
    "    \n",
    "    def forward(self,q,k,v,mask):\n",
    "        query=self.w_q(q) ### batch, seqeunce, dim\n",
    "        key=self.w_k(k)\n",
    "        value=self.w_v(v)\n",
    "\n",
    "        multihead_query=query.view(query.shape[0],query.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        multihead_key=key.view(key.shape[0],key.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        multihead_value=value.view(value.shape[0],value.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        _,contextual_embeddings=multiHeadAttentionBlock.contextual_embedding(multihead_query,multihead_key,multihead_value,self.single_head_dim,mask)\n",
    "        final_contextual_embeddings=contextual_embeddings.transpose(1,2).contiguous().view(value.shape[0],value.shape[1],self.n_heads*self.single_head_dim)\n",
    "        multihead_final_contextual_embedding_proj=self.w_o(final_contextual_embeddings)\n",
    "        dropped_multihead_final_contextual_embedding_proj=self.dropout(multihead_final_contextual_embedding_proj)\n",
    "        return dropped_multihead_final_contextual_embedding_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "399b28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mlab= multiHeadAttentionBlock(6,2,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ecd1facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2090,  0.6333,  1.3828,  0.9443, -0.8652,  0.0000],\n",
       "         [-1.4961,  0.8101,  0.0000, -0.4099, -0.4036, -0.5015],\n",
       "         [-1.1279,  0.1962,  1.0977,  1.0703, -0.5791,  0.5308]],\n",
       "\n",
       "        [[-0.0000, -0.0000, -0.1019, -0.0274,  0.0000,  0.6685],\n",
       "         [-0.2084, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.6294,  0.0000,  0.0000]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=lambda x: Mlab(x,x,x,None)\n",
    "mha_out=a(position_encoded_embedding)\n",
    "mha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "4b5157f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerNormalizationBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim,dtype=torch.float16))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim,dtype=torch.float16))\n",
    "        self.eps=eps\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        standard_deviation=x.std(dim=-1,keepdim=True,unbiased=False)\n",
    "        normalized_x=(x-mean)/(standard_deviation+self.eps)\n",
    "        scale_n_shift=self.scale*normalized_x+self.shift\n",
    "        return scale_n_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ac5fbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnb=layerNormalizationBlock(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "3def1824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4453e+00,  5.1758e-01,  1.3164e+00,  8.4912e-01, -1.0791e+00,\n",
       "          -1.5735e-01],\n",
       "         [-1.6992e+00,  1.6719e+00,  4.8755e-01, -1.1169e-01, -1.0242e-01,\n",
       "          -2.4548e-01],\n",
       "         [-1.6152e+00, -2.2316e-03,  1.0957e+00,  1.0625e+00, -9.4727e-01,\n",
       "           4.0552e-01]],\n",
       "\n",
       "        [[-3.4399e-01, -3.4399e-01, -7.3389e-01, -4.4873e-01, -3.4399e-01,\n",
       "           2.2148e+00],\n",
       "         [-2.2363e+00,  4.4727e-01,  4.4727e-01,  4.4727e-01,  4.4727e-01,\n",
       "           4.4727e-01],\n",
       "         [ 4.4727e-01,  4.4727e-01,  4.4727e-01, -2.2344e+00,  4.4727e-01,\n",
       "           4.4727e-01]]], dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_normalized_out=lnb(mha_out)\n",
    "layer_normalized_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "db6765f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipConnection(nn.Module):\n",
    "    def __init__(self,dropout):\n",
    "        super().__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,sublayer):\n",
    "        output=x+sublayer(x)\n",
    "        dropped_output=self.dropout(output)\n",
    "        return dropped_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "255723d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipConnectionLayer=skipConnection(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0bc5de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.7031,  0.9048, -2.9824,  0.0000, -1.2363, -0.0000],\n",
       "         [ 2.1758,  0.0000,  1.3047,  0.0000,  4.1445, -3.8711],\n",
       "         [ 9.3750, -3.0449, -4.1016, -4.8008,  1.1611,  0.0000]],\n",
       "\n",
       "        [[-0.3081, -0.0000, -0.0000,  0.0000,  6.2344,  4.3906],\n",
       "         [ 3.3125,  0.0000, -1.5723, -0.0180,  0.0000,  5.0938],\n",
       "         [-4.2383, -0.0000,  0.1888, -0.3987,  0.0000, -0.0000]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_connections_output=skipConnectionLayer(position_encoded_embedding,a)\n",
    "skip_connections_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4ca6d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feed_forward_block(nn.Module):\n",
    "    ### Expansion Contraction layer.....\n",
    "    def __init__(self,emb_dim,expand_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.expand_dim=expand_dim\n",
    "        self.dropout=dropout\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(emb_dim,expand_dim,dtype=torch.float16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(expand_dim,emb_dim,dtype=torch.float16),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output=self.network(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e7fdb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffb=feed_forward_block(6,12,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d9b827a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2266e+00,  1.9902e+00, -1.6514e+00,  5.9131e-01, -2.5757e-01,\n",
       "           4.2920e-01],\n",
       "         [-2.1045e-01,  5.7764e-01, -8.7402e-01, -7.4316e-01,  6.8555e-01,\n",
       "          -8.4717e-01],\n",
       "         [ 2.4238e+00,  2.4414e+00, -2.1816e+00,  1.4893e+00, -5.0244e-01,\n",
       "          -4.4580e-01]],\n",
       "\n",
       "        [[-8.7109e-01,  1.0000e+00, -6.9824e-01, -7.1924e-01,  3.5742e-01,\n",
       "          -1.1904e+00],\n",
       "         [ 4.6191e-01,  1.4766e+00, -2.1191e-01, -2.3718e-01,  5.7220e-02,\n",
       "           2.4768e-01],\n",
       "         [-7.5531e-04, -7.1594e-02, -6.1670e-01, -4.2114e-01, -6.5625e-01,\n",
       "          -6.0840e-01]]], dtype=torch.float16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffb_output=ffb(skip_connections_output)\n",
    "ffb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "cb98c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.ff_dropout=ff_dropout\n",
    "        self.expand_dim=expand_dim\n",
    "        self.mha_dropout=mha_dropout\n",
    "        self.sk_dropout=sk_dropout\n",
    "        self.mha_block=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout)\n",
    "        self.feed_forward_block=feed_forward_block(self.emb_dim,self.expand_dim,self.ff_dropout)\n",
    "        self.skip_connections=nn.ModuleList([skipConnection(self.sk_dropout) for _ in range(2)])\n",
    "        self.layerNormalizationBlocks=nn.ModuleList([layerNormalizationBlock(self.emb_dim) for _ in range(2)])\n",
    "    def forward(self,x,mask=None):\n",
    "        output1=self.skip_connections[0](x,lambda x: self.mha_block(x,x,x,mask))\n",
    "        layer_normalized_output1=self.layerNormalizationBlocks[0](output1)\n",
    "        output2=self.skip_connections[1](layer_normalized_output1,self.feed_forward_block)\n",
    "        layer_normalized_output2=self.layerNormalizationBlocks[1](output2)\n",
    "        return layer_normalized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ebbda67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoderBlock(\n",
       "  (mha_block): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (feed_forward_block): feed_forward_block(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (skip_connections): ModuleList(\n",
       "    (0-1): 2 x skipConnection(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layerNormalizationBlocks): ModuleList(\n",
       "    (0-1): 2 x layerNormalizationBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_blk=encoderBlock(6,2,0.3,12,0.3,0.3)\n",
    "enc_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c3ec1a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2754, -0.5693, -1.8574,  1.2549,  0.1554,  0.7417],\n",
       "         [ 0.6211,  0.4089, -1.6514, -0.9795,  1.2910,  0.3101],\n",
       "         [ 1.3115, -0.9668, -1.4072,  1.1611, -0.1322,  0.0338]],\n",
       "\n",
       "        [[-0.8374,  1.6689, -1.4648,  0.0141,  0.6060,  0.0141],\n",
       "         [-0.4473,  2.2363, -0.4473, -0.4473, -0.4473, -0.4473],\n",
       "         [-1.4053, -0.7671, -0.0127,  1.8301,  0.2888,  0.0662]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_blk(ffb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "64360101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self,no_of_enc_blk,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.enc_blks=nn.ModuleList([encoderBlock(emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout) for _ in range(no_of_enc_blk)])\n",
    "    def forward(self,x,mask=None):\n",
    "        for blk in self.enc_blks:\n",
    "            x=blk(x,mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0faa8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (enc_blks): ModuleList(\n",
       "    (0-11): 12 x encoderBlock(\n",
       "      (mha_block): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (feed_forward_block): feed_forward_block(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (skip_connections): ModuleList(\n",
       "        (0-1): 2 x skipConnection(\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNormalizationBlocks): ModuleList(\n",
       "        (0-1): 2 x layerNormalizationBlock()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc=encoder(12,6,2,0.3,12,0.3,0.3)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4ab7cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1231, -0.1997, -1.8223,  1.2754, -0.1231,  0.9932],\n",
       "         [ 0.1295,  1.3604, -1.9346, -0.0135, -0.1492,  0.6079],\n",
       "         [-0.1536, -1.5244,  0.0087,  1.8965, -0.2368,  0.0087]],\n",
       "\n",
       "        [[-1.4580, -0.3865, -0.3865, -0.3865,  1.3184,  1.3008],\n",
       "         [-0.4028,  2.2168, -0.2942, -0.3960, -0.4028, -0.7202],\n",
       "         [-1.6631,  0.7266,  0.3240,  1.0186,  0.6572, -1.0625]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output=enc(ffb_output)\n",
    "enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6a728f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.ff_dropout=ff_dropout\n",
    "        self.expand_dim=expand_dim\n",
    "        self.mha_dropout=mha_dropout\n",
    "        self.sk_dropout=sk_dropout\n",
    "        self.mha_block1=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout) ### casual attention block\n",
    "        self.mha_block2=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout) #### cross attention block\n",
    "        self.feed_forward_block=feed_forward_block(self.emb_dim,self.expand_dim,self.ff_dropout)\n",
    "        self.skip_connections=nn.ModuleList([skipConnection(self.sk_dropout) for _ in range(3)])\n",
    "        self.layerNormalizationBlocks=nn.ModuleList([layerNormalizationBlock(self.emb_dim) for _ in range(3)])\n",
    "    def forward(self,x,enc_out,mask1=None,mask2=None):\n",
    "        output1=self.skip_connections[0](x,lambda x: self.mha_block1(x,x,x,mask1))\n",
    "        layer_normalized_output1=self.layerNormalizationBlocks[0](output1)\n",
    "        output2=self.skip_connections[1](layer_normalized_output1,lambda x: self.mha_block2(x,enc_out,enc_out,mask2))\n",
    "        layer_normalized_output2=self.layerNormalizationBlocks[1](output2)\n",
    "        output3=self.skip_connections[2](layer_normalized_output2,self.feed_forward_block)\n",
    "        layer_normalized_output3=self.layerNormalizationBlocks[2](output3)\n",
    "        return layer_normalized_output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "221702c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoderBlock(\n",
       "  (mha_block1): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (mha_block2): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (feed_forward_block): feed_forward_block(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (skip_connections): ModuleList(\n",
       "    (0-2): 3 x skipConnection(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layerNormalizationBlocks): ModuleList(\n",
       "    (0-2): 3 x layerNormalizationBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_blk=decoderBlock(6,2,0.3,12,0.3,0.3)\n",
    "dec_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "433e0710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6221, -0.4219, -1.6514,  0.6655, -0.1063, -0.1063],\n",
       "         [-0.8452,  2.1895, -0.3579, -0.2430, -0.5000, -0.2430],\n",
       "         [ 1.8447,  0.1548, -0.1047, -0.1047, -1.5840, -0.2065]],\n",
       "\n",
       "        [[ 0.1368,  0.8843, -1.2129,  0.2515,  1.3232, -1.3828],\n",
       "         [ 1.9453, -0.0217, -0.2496, -0.3293,  0.0839, -1.4287],\n",
       "         [-0.1083,  0.3723, -1.7051,  1.6074,  0.3306, -0.4980]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_blk_out=dec_blk(ffb_output,ffb_output)\n",
    "dec_blk_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c11614b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self,no_of_dec_blk,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.dec_blks=nn.ModuleList([decoderBlock(emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout) for _ in range(no_of_dec_blk)])\n",
    "    def forward(self,x,mask=None):\n",
    "        for blk in self.dec_blks:\n",
    "            x=blk(x,mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5b549c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder(\n",
       "  (dec_blks): ModuleList(\n",
       "    (0-11): 12 x decoderBlock(\n",
       "      (mha_block1): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (mha_block2): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (feed_forward_block): feed_forward_block(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (skip_connections): ModuleList(\n",
       "        (0-2): 3 x skipConnection(\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNormalizationBlocks): ModuleList(\n",
       "        (0-2): 3 x layerNormalizationBlock()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec=decoder(12,6,2,0.3,12,0.3,0.3)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "1b3427a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5117,  1.6250, -1.4395, -0.0368,  0.8745, -0.5117],\n",
       "         [ 1.5742,  0.5850, -1.7383, -0.0119, -0.0119, -0.3965],\n",
       "         [-0.3464, -1.3574, -0.3464,  1.8770, -0.3464,  0.5195]],\n",
       "\n",
       "        [[ 0.2954,  1.3076, -1.8916,  0.4050,  0.4192, -0.5347],\n",
       "         [ 0.2145,  0.2145, -1.5996, -0.7158,  1.6719,  0.2145],\n",
       "         [ 1.3438,  0.6050,  0.0032,  0.0032, -1.9580,  0.0032]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output=dec(ffb_output,ffb_output)\n",
    "dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "480ad90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class finalProjectionLayer(nn.Module):\n",
    "    def __init__(self,emb_dim,vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(emb_dim,vocab_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output=self.linear(x)\n",
    "        return output\n",
    "###batch,seq,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformers(nn.Module):\n",
    "    def __init__(self,model_config,tokenizer_config):\n",
    "        super().__init__()\n",
    "        self.encoder_emb_layer=inputEmbeddingLayer(tokenizer_config['vocab_size'],model_config['enc_cfg']['emb_dim'])\n",
    "        self.enc_positional_emb_layer=positionalEncodingLayer(model_config['enc_max_seq_len'],model_config['enc_cfg']['emb_dim'],model_config['enc_cfg']['pos_emb_dropout'])\n",
    "        self.encoder=encoder(\n",
    "            no_of_enc_blk=model_config['enc_cfg']['no_of_enc_blk'],\n",
    "            emb_dim=model_config['enc_cfg']['emb_dim'],\n",
    "            n_heads=model_config['enc_cfg']['n_heads'],\n",
    "            mha_dropout=model_config['enc_cfg']['mha_dropout'],\n",
    "            expand_dim=model_config['enc_cfg']['expand_dim'],\n",
    "            ff_dropout=model_config['enc_cfg']['ff_dropout'],\n",
    "            sk_dropout=model_config['enc_cfg']['sk_dropout']\n",
    "        )\n",
    "        \n",
    "        self.decoder_emb_layer=inputEmbeddingLayer(tokenizer_config['vocab_size'],model_config['dec_cfg']['emb_dim'])\n",
    "        self.dec_positional_emb_layer=positionalEncodingLayer(model_config['dec_max_seq_len'],model_config['dec_cfg']['emb_dim'],model_config['dec_cfg']['pos_emb_dropout'])\n",
    "        self.decoder=decoder(\n",
    "            no_of_dec_blk=model_config['dec_cfg']['no_of_dec_blk'],\n",
    "            emb_dim=model_config['dec_cfg']['emb_dim'],\n",
    "            n_heads=model_config['dec_cfg']['n_heads'],\n",
    "            mha_dropout=model_config['dec_cfg']['mha_dropout'],\n",
    "            expand_dim=model_config['dec_cfg']['expand_dim'],\n",
    "            ff_dropout=model_config['dec_cfg']['ff_dropout'],\n",
    "            sk_dropout=model_config['dec_cfg']['sk_dropout']\n",
    "        )\n",
    "        self.decoder_final_projection=finalProjectionLayer(model_config['dec_cfg']['emb_dim'],tokenizer_config['vocab_size'])\n",
    "\n",
    "    def encode(self,x,mask=None):\n",
    "        encoder_input_embedding=self.encoder_emb_layer(x)\n",
    "        positional_encoded_input_embedding=self.enc_positional_emb_layer(encoder_input_embedding)\n",
    "        encoder_contexual_embedding=self.encoder(positional_encoded_input_embedding,mask)\n",
    "        return encoder_contexual_embedding\n",
    "\n",
    "    def decode(self,x,encoder_output,mask1=None,mask2=None):\n",
    "        decoder_input_embedding=self.decoder_emb_layer(x)\n",
    "        positional_encoded_input_embedding=self.dec_positional_emb_layer(decoder_input_embedding)\n",
    "        decoder_contexual_embedding=self.decoder(positional_encoded_input_embedding,encoder_output,mask1,mask2)\n",
    "        final_output=self.decoder_final_projection(decoder_contexual_embedding)\n",
    "        return final_output\n",
    "    \n",
    "    ###forward will be used during training.\n",
    "    def forward(self,encoder_input,decoder_input,src_mask,tgt_mask):\n",
    "        encoder_output=self.encode(encoder_input,src_mask)\n",
    "        decoder_output=self.decode(decoder_input,encoder_output,src_mask,tgt_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "14f3b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration dictionary\n",
    "model_config = {\n",
    "    \"enc_max_seq_len\": 128,   # Max source sequence length\n",
    "    \"dec_max_seq_len\": 128,   # Max target sequence length\n",
    "    \"enc_cfg\": {\n",
    "        \"emb_dim\": 512,\n",
    "        \"no_of_enc_blk\": 6,\n",
    "        \"n_heads\": 8,\n",
    "        \"pos_emb_dropout\":0.1,\n",
    "        \"mha_dropout\": 0.1,\n",
    "        \"expand_dim\": 2048,\n",
    "        \"ff_dropout\": 0.1,\n",
    "        \"sk_dropout\": 0.1\n",
    "    },\n",
    "    \"dec_cfg\": {\n",
    "        \"emb_dim\": 512,\n",
    "        \"no_of_dec_blk\": 6,\n",
    "        \"pos_emb_dropout\":0.1,\n",
    "        \"n_heads\": 8,\n",
    "        \"mha_dropout\": 0.1,\n",
    "        \"expand_dim\": 2048,\n",
    "        \"ff_dropout\": 0.1,\n",
    "        \"sk_dropout\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tokenizer configuration dictionary\n",
    "tokenizer_config = {\n",
    "    \"vocab_size\": 32000,  # Vocabulary size of source & target tokenizer\n",
    "    \"pad_token_id\": 0,\n",
    "    \"bos_token_id\": 1,\n",
    "    \"eos_token_id\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cb12df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "with open(\"model_config.json\", \"w\") as f:\n",
    "    json.dump(model_config, f, indent=4)\n",
    "\n",
    "with open(\"tokenizer_config.json\", \"w\") as f:\n",
    "    json.dump(tokenizer_config, f, indent=4)\n",
    "\n",
    "# Load\n",
    "with open(\"model_config.json\", \"r\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "with open(\"tokenizer_config.json\", \"r\") as f:\n",
    "    tokenizer_config = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5f51e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers(\n",
       "  (encoder_emb_layer): inputEmbeddingLayer(\n",
       "    (embedding_layer): Embedding(32000, 512)\n",
       "  )\n",
       "  (enc_positional_emb_layer): positionalEncodingLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): encoder(\n",
       "    (enc_blks): ModuleList(\n",
       "      (0-5): 6 x encoderBlock(\n",
       "        (mha_block): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): feed_forward_block(\n",
       "          (network): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (skip_connections): ModuleList(\n",
       "          (0-1): 2 x skipConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layerNormalizationBlocks): ModuleList(\n",
       "          (0-1): 2 x layerNormalizationBlock()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_emb_layer): inputEmbeddingLayer(\n",
       "    (embedding_layer): Embedding(32000, 512)\n",
       "  )\n",
       "  (dec_positional_emb_layer): positionalEncodingLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): decoder(\n",
       "    (dec_blks): ModuleList(\n",
       "      (0-5): 6 x decoderBlock(\n",
       "        (mha_block1): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mha_block2): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): feed_forward_block(\n",
       "          (network): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (skip_connections): ModuleList(\n",
       "          (0-2): 3 x skipConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layerNormalizationBlocks): ModuleList(\n",
       "          (0-2): 3 x layerNormalizationBlock()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_final_projection): finalProjectionLayer(\n",
       "    (linear): Linear(in_features=512, out_features=32000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformer=transformers(model_config,tokenizer_config)\n",
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
