{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "4e709dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdfb9b",
   "metadata": {},
   "source": [
    "### DATA PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "191d27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ingestion():\n",
    "    ds = load_dataset(path=\"Helsinki-NLP/opus_books\", name=\"en-fr\")\n",
    "    train_test_data=ds['train'].train_test_split(test_size=0.2,seed=42)\n",
    "    test_data=train_test_data['test']\n",
    "    train_val_split=train_test_data['train'].train_test_split(test_size=0.2,seed=42)\n",
    "    train_data=train_val_split['train']\n",
    "    validation_data=train_val_split['test']\n",
    "    return train_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "7e7dcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,validation_data,test_data=data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "afd224d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'translation'],\n",
       "    num_rows: 25417\n",
       "})"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "validation_data\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "ade64c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '61261',\n",
       " 'translation': {'en': 'One morning, on awaking, she saw on her window two vases filled with flowers.',\n",
       "  'fr': 'Un matin, elle vit, en s’éveillant, sur sa fenêtre, deux vases pleins de fleurs.'}}"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "733140df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '61261',\n",
       " 'translation': {'en': 'One morning, on awaking, she saw on her window two vases filled with flowers.',\n",
       "  'fr': 'Un matin, elle vit, en s’éveillant, sur sa fenêtre, deux vases pleins de fleurs.'}}"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "06df60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathlib\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "6d9b2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(ds,lang):\n",
    "    for pair in ds:\n",
    "        # print(pair)\n",
    "        yield pair['translation'][lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "5d7ed016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_all_sentences at 0x000002572E168E10>"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_sentences(train_data,'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "fbc37458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(config,ds,lang):\n",
    "    tokenizer_path=Path(config['tokenizer_file'].format(lang))\n",
    "    \n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer=Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "        tokenizer.pre_tokenizer=Whitespace()\n",
    "        trainer=WordLevelTrainer(special_tokens=[\"[UNK]\",\"[PAD]\",\"[SOS]\",\"[EOS]\"],min_frequency=1)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds,lang),trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer=Tokenizer.from_file(str(tokenizer_path))\n",
    "    \n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "9031a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en=build_tokenizer({'tokenizer_file':'tokenizer_en.json'},train_data,'en')\n",
    "tokenizer_fr=build_tokenizer({'tokenizer_file':'tokenizer_fr.json'},train_data,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_seq_len(train_data,test_data,validation_data):\n",
    "    max_len=0\n",
    "    for data in train_data:\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['en']).ids))\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['fr']).ids))\n",
    "\n",
    "    for data in test_data:\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['en']).ids))\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['fr']).ids))\n",
    "\n",
    "    for data in validation_data:\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['en']).ids))\n",
    "        max_len=max(max_len,len(tokenizer.encode(data['translation']['fr']).ids))\n",
    "\n",
    "    return max_len    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "29682a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True,  True,  True])"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([2,3,5,0,0,0])\n",
    "x==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "59cd0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tokenizer.encode(\"Hello mahi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "fb092dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "b44ffe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_SEQ_LEN 482\n"
     ]
    }
   ],
   "source": [
    "max_seq_len=get_max_seq_len(train_data,test_data,validation_data)\n",
    "print(\"Max_SEQ_LEN\",max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "40dcd62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cat(\n",
    "    [\n",
    "        torch.tensor([1]),\n",
    "        torch.tensor([2,3,4]),\n",
    "        torch.tensor([4]*3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "44f05411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "fd1cada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 4]"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[4]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "f4e0d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class opusDataset_En_to_Fr(Dataset):\n",
    "    def __init__(self,data,max_seq_len,tokenizer_en,tokenizer_fr):\n",
    "        super().__init__()\n",
    "        self.raw_data=data\n",
    "        self.tokenizer_en=tokenizer_en\n",
    "        self.tokenizer_fr=tokenizer_fr\n",
    "\n",
    "\n",
    "        ### Goal Shoould be to set a max length that fits all the sequence..\n",
    "        self.max_seq_len=max_seq_len\n",
    "        self.sos_token=torch.tensor([self.tokenizer_en.token_to_id(\"[SOS]\")],dtype=torch.int64)\n",
    "        self.eos_token=torch.tensor([self.tokenizer_en.token_to_id(\"[EOS]\")],dtype=torch.int64)\n",
    "        self.pad_token=torch.tensor([self.tokenizer_en.token_to_id(\"[PAD]\")],dtype=torch.int64)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_en=self.raw_data[index]['translation']['en']\n",
    "        data_fr=self.raw_data[index]['translation']['fr']\n",
    "        encoded_data_en=torch.tensor(self.tokenizer_en.encode(data_en).ids,dtype=torch.int64)\n",
    "        encoded_data_fr=torch.tensor(self.tokenizer_fr.encode(data_fr).ids,dtype=torch.int64)\n",
    "        expected_seq_len=self.max_seq_len+2\n",
    "\n",
    "        final_encoded_en=torch.cat([\n",
    "            self.sos_token,\n",
    "            encoded_data_en,\n",
    "            self.eos_token,\n",
    "            torch.tensor([self.pad_token]*(expected_seq_len-len(encoded_data_en)-2)),\n",
    "\n",
    "        ]\n",
    "        )\n",
    "        final_encoded_fr=torch.cat([\n",
    "            self.sos_token,\n",
    "            encoded_data_fr,\n",
    "            torch.tensor([self.pad_token]*(expected_seq_len-len(encoded_data_fr)-1))\n",
    "        ])\n",
    "\n",
    "\n",
    "        target_encoded_fr=torch.cat([\n",
    "            self.sos_token,\n",
    "            encoded_data_fr,\n",
    "            self.eos_token,\n",
    "            torch.tensor([self.pad_token]*(expected_seq_len-len(encoded_data_fr)-2)),\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "            'encoder_input':final_encoded_en,\n",
    "            'decoder_input':final_encoded_fr,\n",
    "            'target_output':target_encoded_fr,\n",
    "            'encoder_mask': (final_encoded_en!=self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
    "            'decodar_mask': (target_encoded_fr!=self.pad_token).unsqueeze(0).unsqueeze(0).int() & casual_mask_generator(len(target_encoded_fr)),\n",
    "            'src_sentance':data_en,\n",
    "            'tgt_sentence':data_fr,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "0bc91c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 5, 0, 0, 0]])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([[2,1,5,0,0,0]],dtype=int)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "87bfcf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True, False, False, False]]]])"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a!=0).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "becb80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=opusDataset_En_to_Fr(train_data,max_seq_len,tokenizer_en,tokenizer_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "dd2c7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=opusDataset_En_to_Fr(test_data,max_seq_len,tokenizer_en,tokenizer_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "779833d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset=opusDataset_En_to_Fr(validation_data,max_seq_len,tokenizer_en,tokenizer_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "a42a5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=2,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=2,shuffle=False)\n",
    "val_loader=DataLoader(validation_dataset,batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "d55e451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   11, 3307,   23,    6,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1],\n",
      "        [   2,   21, 9583,  441,   49,  751,    4,   84, 3516,    9, 5416,    4,\n",
      "            9,    5, 2272,   14,  743,    6,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch in train_loader:\n",
    "    if i==1:\n",
    "        break\n",
    "    else:\n",
    "        i+=1\n",
    "        print(batch['encoder_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "8468ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fca650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "7ed518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputEmbeddingLayer(nn.Module):\n",
    "    def __init__(self,vocab_size,emb_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.emb_dim=emb_dim\n",
    "        self.embedding_layer=nn.Embedding(self.vocab_size,self.emb_dim,dtype=torch.float16)\n",
    "    def forward(self,x):\n",
    "        embeddings=self.embedding_layer(x)\n",
    "        return embeddings*math.sqrt(self.emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "f724db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer=inputEmbeddingLayer(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "4c0416b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4971,  3.7383,  3.4277, -3.5527,  2.1113,  1.4219],\n",
       "         [ 1.3105, -1.2568, -1.1025,  2.2109, -2.0371, -2.2910],\n",
       "         [ 0.0385,  1.5801,  4.1992, -3.0312, -1.6807,  0.2301]],\n",
       "\n",
       "        [[-0.3394,  2.6738, -1.1416,  1.9004,  2.1152, -4.2539],\n",
       "         [ 3.0801, -0.2170, -2.1250, -1.8135,  2.0781, -1.1641],\n",
       "         [ 3.0898,  1.8047, -2.8652,  5.3164,  2.3828, -1.9258]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input=torch.tensor([[1,2,3],[4,5,6]])\n",
    "input_embeddings=embedding_layer(test_input)\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "38abc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class positionalEncodingLayer(nn.Module):\n",
    "    def __init__(self,max_seq_len,emb_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.max_seq_len=max_seq_len\n",
    "        self.emb_dim=emb_dim\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        static_positional_info=torch.zeros((self.max_seq_len,self.emb_dim),dtype=torch.float16)\n",
    "        positions=torch.arange(0,max_seq_len,dtype=torch.float16).reshape(max_seq_len,-1)\n",
    "        indices_for_denominator=torch.arange(0,emb_dim,2,dtype=torch.float16) ### 2i\n",
    "        denominators=torch.exp((-2*indices_for_denominator*math.log(1e4))/emb_dim)\n",
    "        static_positional_info[:,0::2]=torch.sin(positions*denominators)\n",
    "        static_positional_info[:,1::2]=torch.cos(positions*denominators)\n",
    "        self.register_buffer('static_positional_info',static_positional_info)\n",
    "    def forward(self,x):\n",
    "        position_encoded_embedding=x+self.static_positional_info[:x.shape[1],:]\n",
    "        dropped_embeddings=self.dropout(position_encoded_embedding)\n",
    "        return dropped_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "c3326665",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding_layer=positionalEncodingLayer(3,6,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "83f95915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7100,  6.7695,  4.8984, -0.0000,  0.0000,  3.4609],\n",
       "         [ 0.0000, -1.0234, -0.0000,  4.5859, -2.9102, -0.0000],\n",
       "         [ 1.3545,  1.6631,  0.0000, -0.0000, -2.4004,  1.7578]],\n",
       "\n",
       "        [[-0.4849,  0.0000, -0.0000,  4.1445,  0.0000, -0.0000],\n",
       "         [ 5.6016,  0.4622, -3.0332, -1.1621,  0.0000, -0.0000],\n",
       "         [ 5.7148,  1.9844, -0.0000,  0.0000,  3.4043, -1.3223]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_encoded_embedding=positional_encoding_layer(input_embeddings)\n",
    "position_encoded_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "01dc91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,dropout):\n",
    "        super().__init__()\n",
    "        assert emb_dim%n_heads==0 ### checking if multi head splitting is possible.\n",
    "        self.w_q=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_k=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_v=nn.Linear(emb_dim,emb_dim,dtype=torch.float16)\n",
    "        self.w_o=nn.Linear(emb_dim,emb_dim,dtype=torch.float16) ### multi-head-projection-layer\n",
    "        self.emb_dim=emb_dim\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.single_head_dim=self.emb_dim//n_heads\n",
    "        self.n_heads=n_heads\n",
    "\n",
    "    @staticmethod\n",
    "    def contextual_embedding(m_q,m_k,m_v,per_head_emb_dim,mask):\n",
    "        ### return contexual embedding and attention scores\n",
    "        attention_scores=m_q@m_k.transpose(2,3)/math.sqrt(per_head_emb_dim)\n",
    "        ##batch,head,seq,dim @ batch,head,dim,seq==batch,head,seq,seq\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask==0,value=float('-inf'))\n",
    "        normalized_attention_scores=torch.softmax(attention_scores,dim=-1)\n",
    "        ### batch,head,seq,seq @ batch,head,seq,dim=batch,head,seq,dim\n",
    "        contexual_embeddings=normalized_attention_scores@m_v\n",
    "        return normalized_attention_scores,contexual_embeddings\n",
    "    \n",
    "    def forward(self,q,k,v,mask):\n",
    "        query=self.w_q(q) ### batch, seqeunce, dim\n",
    "        key=self.w_k(k)\n",
    "        value=self.w_v(v)\n",
    "\n",
    "        multihead_query=query.view(query.shape[0],query.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        multihead_key=key.view(key.shape[0],key.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        multihead_value=value.view(value.shape[0],value.shape[1],self.n_heads,self.single_head_dim).transpose(1,2)\n",
    "        _,contextual_embeddings=multiHeadAttentionBlock.contextual_embedding(multihead_query,multihead_key,multihead_value,self.single_head_dim,mask)\n",
    "        final_contextual_embeddings=contextual_embeddings.transpose(1,2).contiguous().view(value.shape[0],value.shape[1],self.n_heads*self.single_head_dim)\n",
    "        multihead_final_contextual_embedding_proj=self.w_o(final_contextual_embeddings)\n",
    "        dropped_multihead_final_contextual_embedding_proj=self.dropout(multihead_final_contextual_embedding_proj)\n",
    "        return dropped_multihead_final_contextual_embedding_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "399b28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mlab= multiHeadAttentionBlock(6,2,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "ecd1facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0244,  0.0000, -0.0044,  0.0000,  0.0000,  0.2698],\n",
       "         [-1.9434,  0.7710, -0.7910,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.4121,  0.3752,  0.5352,  1.5469,  0.0000,  0.2651]],\n",
       "\n",
       "        [[-0.0000, -0.0000,  1.0186,  0.7993,  1.9961,  0.0000],\n",
       "         [-1.7383, -0.7485,  1.2539,  0.0000,  2.2695,  0.9678],\n",
       "         [-0.0000, -0.6299,  1.0225,  0.9409,  0.0000,  0.9648]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=lambda x: Mlab(x,x,x,None)\n",
    "mha_out=a(position_encoded_embedding)\n",
    "mha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "3191b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 6])"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "4b5157f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerNormalizationBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim,dtype=torch.float16))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim,dtype=torch.float16))\n",
    "        self.eps=eps\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        standard_deviation=x.std(dim=-1,keepdim=True,unbiased=False)\n",
    "        normalized_x=(x-mean)/(standard_deviation+self.eps)\n",
    "        scale_n_shift=self.scale*normalized_x+self.shift\n",
    "        return scale_n_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "ac5fbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnb=layerNormalizationBlock(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "3def1824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1719,  0.3057,  0.2954,  0.3057,  0.3057,  0.9580],\n",
       "         [-1.8965,  1.2881, -0.5444,  0.3840,  0.3840,  0.3840],\n",
       "         [-1.8633,  0.1792,  0.3621,  1.5166, -0.2494,  0.0534]],\n",
       "\n",
       "        [[-0.8657, -0.8657,  0.5215,  0.2228,  1.8525, -0.8657],\n",
       "         [-1.5615, -0.8154,  0.6934, -0.2517,  1.4580,  0.4775],\n",
       "         [-0.6084, -1.6094,  1.0166,  0.8857, -0.6084,  0.9248]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_normalized_out=lnb(mha_out)\n",
    "layer_normalized_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "db6765f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipConnection(nn.Module):\n",
    "    def __init__(self,dropout):\n",
    "        super().__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,sublayer):\n",
    "        output=x+sublayer(x)\n",
    "        dropped_output=self.dropout(output)\n",
    "        return dropped_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "255723d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipConnectionLayer=skipConnection(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "0bc5de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4785, 10.6016,  6.9922,  0.3186,  0.2542,  0.0000],\n",
       "         [ 0.0000, -0.3606, -1.1299,  7.6523, -0.0000,  1.9033],\n",
       "         [-0.0000,  2.9141,  0.0000,  0.0000, -3.4297,  0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.0000,  0.0000,  0.0000,  2.8516,  0.0000],\n",
       "         [ 0.0000, -0.0000, -2.5430, -0.1968,  0.0000,  1.3828],\n",
       "         [ 0.0000,  1.9355,  1.4609,  0.0000,  7.9023, -1.8887]]],\n",
       "       dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_connections_output=skipConnectionLayer(position_encoded_embedding,a)\n",
    "skip_connections_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "4ca6d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feed_forward_block(nn.Module):\n",
    "    ### Expansion Contraction layer.....\n",
    "    def __init__(self,emb_dim,expand_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.expand_dim=expand_dim\n",
    "        self.dropout=dropout\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(emb_dim,expand_dim,dtype=torch.float16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(expand_dim,emb_dim,dtype=torch.float16),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output=self.network(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "e7fdb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffb=feed_forward_block(6,12,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "d9b827a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9121, -1.2197, -0.3979, -2.3574, -0.8320,  0.1094],\n",
       "         [ 0.0396,  0.0464, -1.2646,  0.8452,  1.5117,  0.1829],\n",
       "         [ 0.7300, -0.2017,  0.3567, -0.1979,  0.2361, -0.5698]],\n",
       "\n",
       "        [[-0.0369,  0.0201, -0.1624, -0.1514,  0.2144,  0.1747],\n",
       "         [ 0.4355,  0.5513, -0.8926, -0.3479,  0.4580,  0.4985],\n",
       "         [ 0.4045,  0.6255, -0.1118, -0.5366, -0.0368,  0.4282]]],\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffb_output=ffb(skip_connections_output)\n",
    "ffb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "cb98c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.ff_dropout=ff_dropout\n",
    "        self.expand_dim=expand_dim\n",
    "        self.mha_dropout=mha_dropout\n",
    "        self.sk_dropout=sk_dropout\n",
    "        self.mha_block=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout)\n",
    "        self.feed_forward_block=feed_forward_block(self.emb_dim,self.expand_dim,self.ff_dropout)\n",
    "        self.skip_connections=nn.ModuleList([skipConnection(self.sk_dropout) for _ in range(2)])\n",
    "        self.layerNormalizationBlocks=nn.ModuleList([layerNormalizationBlock(self.emb_dim) for _ in range(2)])\n",
    "    def forward(self,x,mask=None):\n",
    "        output1=self.skip_connections[0](x,lambda x: self.mha_block(x,x,x,mask))\n",
    "        layer_normalized_output1=self.layerNormalizationBlocks[0](output1)\n",
    "        output2=self.skip_connections[1](layer_normalized_output1,self.feed_forward_block)\n",
    "        layer_normalized_output2=self.layerNormalizationBlocks[1](output2)\n",
    "        return layer_normalized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "ebbda67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoderBlock(\n",
       "  (mha_block): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (feed_forward_block): feed_forward_block(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (skip_connections): ModuleList(\n",
       "    (0-1): 2 x skipConnection(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layerNormalizationBlocks): ModuleList(\n",
       "    (0-1): 2 x layerNormalizationBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_blk=encoderBlock(6,2,0.3,12,0.3,0.3)\n",
    "enc_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "c3ec1a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2090, -0.3611, -0.3611, -0.3611, -0.7798, -0.3452],\n",
       "         [-0.6875, -0.2578, -0.8335,  0.3860,  2.0469, -0.6528],\n",
       "         [-2.1445,  0.9966,  0.3716,  0.3716,  0.0321,  0.3716]],\n",
       "\n",
       "        [[-0.0740,  0.0399, -1.1543, -0.7588,  2.0195, -0.0740],\n",
       "         [ 0.2122,  0.1542, -2.1738,  0.8398,  0.5986,  0.3696],\n",
       "         [ 0.4985, -0.2952, -1.8164,  0.1155, -0.0337,  1.5322]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_blk(ffb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "64360101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self,no_of_enc_blk,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.enc_blks=nn.ModuleList([encoderBlock(emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout) for _ in range(no_of_enc_blk)])\n",
    "    def forward(self,x,mask=None):\n",
    "        for blk in self.enc_blks:\n",
    "            x=blk(x,mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "0faa8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (enc_blks): ModuleList(\n",
       "    (0-11): 12 x encoderBlock(\n",
       "      (mha_block): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (feed_forward_block): feed_forward_block(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (skip_connections): ModuleList(\n",
       "        (0-1): 2 x skipConnection(\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNormalizationBlocks): ModuleList(\n",
       "        (0-1): 2 x layerNormalizationBlock()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc=encoder(12,6,2,0.3,12,0.3,0.3)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "4ab7cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9395,  0.2659,  1.1143,  1.4326, -0.9336, -0.9395],\n",
       "         [-0.3936, -0.1971,  0.0848,  2.0176, -1.2998, -0.2124],\n",
       "         [-0.4470, -0.4470,  2.2344, -0.4470, -0.4470, -0.4470]],\n",
       "\n",
       "        [[-0.1855,  0.4629, -2.1152,  0.6787,  0.3123,  0.8477],\n",
       "         [-0.6445, -0.2800, -0.4331,  2.2227, -0.4331, -0.4331],\n",
       "         [-0.2444, -0.2078, -0.4307, -0.7979, -0.5132,  2.1934]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output=enc(ffb_output)\n",
    "enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "6a728f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    def __init__(self,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim=emb_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.ff_dropout=ff_dropout\n",
    "        self.expand_dim=expand_dim\n",
    "        self.mha_dropout=mha_dropout\n",
    "        self.sk_dropout=sk_dropout\n",
    "        self.mha_block1=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout) ### casual attention block\n",
    "        self.mha_block2=multiHeadAttentionBlock(self.emb_dim,self.n_heads,self.mha_dropout) #### cross attention block\n",
    "        self.feed_forward_block=feed_forward_block(self.emb_dim,self.expand_dim,self.ff_dropout)\n",
    "        self.skip_connections=nn.ModuleList([skipConnection(self.sk_dropout) for _ in range(3)])\n",
    "        self.layerNormalizationBlocks=nn.ModuleList([layerNormalizationBlock(self.emb_dim) for _ in range(3)])\n",
    "    def forward(self,x,enc_out,mask1=None,mask2=None):\n",
    "        output1=self.skip_connections[0](x,lambda x: self.mha_block1(x,x,x,mask1))\n",
    "        layer_normalized_output1=self.layerNormalizationBlocks[0](output1)\n",
    "        output2=self.skip_connections[1](layer_normalized_output1,lambda x: self.mha_block2(x,enc_out,enc_out,mask2))\n",
    "        layer_normalized_output2=self.layerNormalizationBlocks[1](output2)\n",
    "        output3=self.skip_connections[2](layer_normalized_output2,self.feed_forward_block)\n",
    "        layer_normalized_output3=self.layerNormalizationBlocks[2](output3)\n",
    "        return layer_normalized_output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "221702c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoderBlock(\n",
       "  (mha_block1): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (mha_block2): multiHeadAttentionBlock(\n",
       "    (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (feed_forward_block): feed_forward_block(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (skip_connections): ModuleList(\n",
       "    (0-2): 3 x skipConnection(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layerNormalizationBlocks): ModuleList(\n",
       "    (0-2): 3 x layerNormalizationBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_blk=decoderBlock(6,2,0.3,12,0.3,0.3)\n",
    "dec_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "433e0710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9668, -0.3589, -0.0656, -1.4111, -0.0656, -0.0656],\n",
       "         [-0.4863, -1.2588,  1.2754, -0.4863,  1.4434, -0.4863],\n",
       "         [-0.2219, -0.2219,  0.0309,  2.0176, -0.2803, -1.3242]],\n",
       "\n",
       "        [[-0.7681, -0.8442, -0.1487, -0.1487,  2.1445, -0.2349],\n",
       "         [ 0.8345, -1.0762, -1.5723,  0.2776,  0.3105,  1.2256],\n",
       "         [ 0.5034,  0.5034,  0.5796,  0.1215, -2.2109,  0.5034]]],\n",
       "       dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_blk_out=dec_blk(ffb_output,ffb_output)\n",
    "dec_blk_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "c11614b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self,no_of_dec_blk,emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout):\n",
    "        super().__init__()\n",
    "        self.dec_blks=nn.ModuleList([decoderBlock(emb_dim,n_heads,mha_dropout,expand_dim,ff_dropout,sk_dropout) for _ in range(no_of_dec_blk)])\n",
    "    def forward(self,x,encoder_output,decoder_mask,encoder_mask):\n",
    "        for blk in self.dec_blks:\n",
    "            x=blk(x,encoder_output,decoder_mask=None,encoder_mask=None)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "5b549c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder(\n",
       "  (dec_blks): ModuleList(\n",
       "    (0-11): 12 x decoderBlock(\n",
       "      (mha_block1): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (mha_block2): multiHeadAttentionBlock(\n",
       "        (w_q): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_k): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_v): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (w_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (feed_forward_block): feed_forward_block(\n",
       "        (network): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (skip_connections): ModuleList(\n",
       "        (0-2): 3 x skipConnection(\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (layerNormalizationBlocks): ModuleList(\n",
       "        (0-2): 3 x layerNormalizationBlock()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec=decoder(12,6,2,0.3,12,0.3,0.3)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "480ad90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class finalProjectionLayer(nn.Module):\n",
    "    def __init__(self,emb_dim,vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(emb_dim,vocab_size,dtype=torch.float16)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output=self.linear(x)\n",
    "        return output\n",
    "###batch,seq,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "52b7fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformers(nn.Module):\n",
    "    def __init__(self,model_config,tokenizer_config):\n",
    "        super().__init__()\n",
    "        self.encoder_emb_layer=inputEmbeddingLayer(tokenizer_config['vocab_size'],model_config['enc_cfg']['emb_dim'])\n",
    "        self.enc_positional_emb_layer=positionalEncodingLayer(model_config['enc_max_seq_len'],model_config['enc_cfg']['emb_dim'],model_config['enc_cfg']['pos_emb_dropout'])\n",
    "        self.encoder=encoder(\n",
    "            no_of_enc_blk=model_config['enc_cfg']['no_of_enc_blk'],\n",
    "            emb_dim=model_config['enc_cfg']['emb_dim'],\n",
    "            n_heads=model_config['enc_cfg']['n_heads'],\n",
    "            mha_dropout=model_config['enc_cfg']['mha_dropout'],\n",
    "            expand_dim=model_config['enc_cfg']['expand_dim'],\n",
    "            ff_dropout=model_config['enc_cfg']['ff_dropout'],\n",
    "            sk_dropout=model_config['enc_cfg']['sk_dropout']\n",
    "        )\n",
    "        \n",
    "        self.decoder_emb_layer=inputEmbeddingLayer(tokenizer_config['vocab_size'],model_config['dec_cfg']['emb_dim'])\n",
    "        self.dec_positional_emb_layer=positionalEncodingLayer(model_config['dec_max_seq_len'],model_config['dec_cfg']['emb_dim'],model_config['dec_cfg']['pos_emb_dropout'])\n",
    "        self.decoder=decoder(\n",
    "            no_of_dec_blk=model_config['dec_cfg']['no_of_dec_blk'],\n",
    "            emb_dim=model_config['dec_cfg']['emb_dim'],\n",
    "            n_heads=model_config['dec_cfg']['n_heads'],\n",
    "            mha_dropout=model_config['dec_cfg']['mha_dropout'],\n",
    "            expand_dim=model_config['dec_cfg']['expand_dim'],\n",
    "            ff_dropout=model_config['dec_cfg']['ff_dropout'],\n",
    "            sk_dropout=model_config['dec_cfg']['sk_dropout']\n",
    "        )\n",
    "        self.decoder_final_projection=finalProjectionLayer(model_config['dec_cfg']['emb_dim'],tokenizer_config['vocab_size'])\n",
    "\n",
    "    def encode(self,x,mask=None):\n",
    "        encoder_input_embedding=self.encoder_emb_layer(x)\n",
    "        positional_encoded_input_embedding=self.enc_positional_emb_layer(encoder_input_embedding)\n",
    "        encoder_contexual_embedding=self.encoder(positional_encoded_input_embedding,mask)\n",
    "        return encoder_contexual_embedding\n",
    "\n",
    "    def decode(self,x,encoder_output,mask1=None,mask2=None):\n",
    "        decoder_input_embedding=self.decoder_emb_layer(x)\n",
    "        positional_encoded_input_embedding=self.dec_positional_emb_layer(decoder_input_embedding)\n",
    "        decoder_contexual_embedding=self.decoder(positional_encoded_input_embedding,encoder_output,mask1,mask2)\n",
    "        final_output=self.decoder_final_projection(decoder_contexual_embedding)\n",
    "        return final_output\n",
    "    \n",
    "    ###forward will be used during training.\n",
    "    def forward(self,encoder_input,decoder_input,src_mask,tgt_mask):\n",
    "        encoder_output=self.encode(encoder_input,src_mask)\n",
    "        decoder_output=self.decode(decoder_input,encoder_output,src_mask,tgt_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "14f3b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration dictionary\n",
    "model_config = {\n",
    "    \"enc_max_seq_len\": 484,   # Max source sequence length\n",
    "    \"dec_max_seq_len\": 484,   # Max target sequence length\n",
    "    \"enc_cfg\": {\n",
    "        \"emb_dim\": 512,\n",
    "        \"no_of_enc_blk\": 6,\n",
    "        \"n_heads\": 8,\n",
    "        \"pos_emb_dropout\":0.1,\n",
    "        \"mha_dropout\": 0.1,\n",
    "        \"expand_dim\": 2048,\n",
    "        \"ff_dropout\": 0.1,\n",
    "        \"sk_dropout\": 0.1\n",
    "    },\n",
    "    \"dec_cfg\": {\n",
    "        \"emb_dim\": 512,\n",
    "        \"no_of_dec_blk\": 6,\n",
    "        \"pos_emb_dropout\":0.1,\n",
    "        \"n_heads\": 8,\n",
    "        \"mha_dropout\": 0.1,\n",
    "        \"expand_dim\": 2048,\n",
    "        \"ff_dropout\": 0.1,\n",
    "        \"sk_dropout\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tokenizer configuration dictionary\n",
    "tokenizer_config = {\n",
    "    \"vocab_size\": 30000,  # Vocabulary size of source & target tokenizer\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "cb12df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "with open(\"model_config.json\", \"w\") as f:\n",
    "    json.dump(model_config, f, indent=4)\n",
    "\n",
    "with open(\"tokenizer_config.json\", \"w\") as f:\n",
    "    json.dump(tokenizer_config, f, indent=4)\n",
    "\n",
    "# Load\n",
    "with open(\"model_config.json\", \"r\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "with open(\"tokenizer_config.json\", \"r\") as f:\n",
    "    tokenizer_config = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "5f51e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers(\n",
       "  (encoder_emb_layer): inputEmbeddingLayer(\n",
       "    (embedding_layer): Embedding(30000, 512)\n",
       "  )\n",
       "  (enc_positional_emb_layer): positionalEncodingLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): encoder(\n",
       "    (enc_blks): ModuleList(\n",
       "      (0-5): 6 x encoderBlock(\n",
       "        (mha_block): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): feed_forward_block(\n",
       "          (network): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (skip_connections): ModuleList(\n",
       "          (0-1): 2 x skipConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layerNormalizationBlocks): ModuleList(\n",
       "          (0-1): 2 x layerNormalizationBlock()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_emb_layer): inputEmbeddingLayer(\n",
       "    (embedding_layer): Embedding(30000, 512)\n",
       "  )\n",
       "  (dec_positional_emb_layer): positionalEncodingLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): decoder(\n",
       "    (dec_blks): ModuleList(\n",
       "      (0-5): 6 x decoderBlock(\n",
       "        (mha_block1): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mha_block2): multiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): feed_forward_block(\n",
       "          (network): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (skip_connections): ModuleList(\n",
       "          (0-2): 3 x skipConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layerNormalizationBlocks): ModuleList(\n",
       "          (0-2): 3 x layerNormalizationBlock()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_final_projection): finalProjectionLayer(\n",
       "    (linear): Linear(in_features=512, out_features=30000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformer=transformers(model_config,tokenizer_config)\n",
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "3bb6d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def casual_mask_generator(size):\n",
    "    mask=torch.triu(torch.ones(1,size,size),diagonal=1).type(torch.int)\n",
    "    return mask==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3586fd",
   "metadata": {},
   "source": [
    "### Inference Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "0277babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def gready_decode(model,src,src_mask,tokenizer_src,tokenizer_tgt,max_len,device):\n",
    "    sos_idx=tokenizer_tgt.token_to_id('[SOS]')\n",
    "    eos_idx=tokenizer_tgt.token_to_id('[EOS]')\n",
    "\n",
    "    encoder_output=model.encode(src,src_mask)\n",
    "    decoder_input=torch.empty(1,1).fill_(sos_idx).type_as(src).to(device)\n",
    "\n",
    "    while True:\n",
    "        if decoder_input.size(1)==max_len:\n",
    "            break\n",
    "\n",
    "        decoder_mask=casual_mask_generator(decoder_input.size(1)).type_as(src_mask).to(device)\n",
    "\n",
    "        out=model.decode(decoder_input,encoder_output,src_mask,decoder_mask)\n",
    "\n",
    "        prob=model.project(out[:,-1])\n",
    "\n",
    "        _,next_word=torch.max(prob,dim=1)\n",
    "\n",
    "        decoder_input=torch.cat((decoder_input,[next_word]),dim=1).type_as(src).to(device)\n",
    "\n",
    "        if next_word==eos_idx:\n",
    "            break\n",
    "\n",
    "    return decoder_input.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "55225090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4630c1",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "be498b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device {device}\")\n",
    "\n",
    "    optimizer=torch.optim.Adam(Transformer.parameters(), lr=1e-4, eps = 1e-9)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_en.token_to_id('[PAD]'), label_smoothing = 0.1).to(device)\n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "\n",
    "    epoch=3\n",
    "\n",
    "    for i in range(epoch):\n",
    "        for batch in train_loader:\n",
    "            encoder_input=batch['encoder_input'].to(device)\n",
    "            decoder_input=batch['decoder_input'].to(device)\n",
    "            target_output=batch['target_output'].to(device)\n",
    "            encoder_mask=batch['encoder_mask'].to(device)\n",
    "            decoder_mask=batch['decodar_mask'].to(device)\n",
    "            src_sentence=batch['src_sentance']\n",
    "            tgt_sentence=batch['tgt_sentence']\n",
    "\n",
    "            encoder_output=Transformer.encode(encoder_input,encoder_mask)\n",
    "            decoder_output=Transformer.decode(decoder_input,encoder_output,decoder_mask,encoder_mask)\n",
    "            proj_output=Transformer.decoder_final_projection(decoder_output)\n",
    "            loss = loss_fn(proj_output.view(-1, tokenizer_fr.get_vocab_size()), label.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step+=1\n",
    "            print('ko')\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "1554a595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "decoderBlock.forward() got an unexpected keyword argument 'decoder_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[902]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[901]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m tgt_sentence=batch[\u001b[33m'\u001b[39m\u001b[33mtgt_sentence\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m encoder_output=Transformer.encode(encoder_input,encoder_mask)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m decoder_output=\u001b[43mTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m proj_output=Transformer.decoder_final_projection(decoder_output)\n\u001b[32m     25\u001b[39m loss = loss_fn(proj_output.view(-\u001b[32m1\u001b[39m, tokenizer_fr.get_vocab_size()), label.view(-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[893]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtransformers.decode\u001b[39m\u001b[34m(self, x, encoder_output, mask1, mask2)\u001b[39m\n\u001b[32m     36\u001b[39m decoder_input_embedding=\u001b[38;5;28mself\u001b[39m.decoder_emb_layer(x)\n\u001b[32m     37\u001b[39m positional_encoded_input_embedding=\u001b[38;5;28mself\u001b[39m.dec_positional_emb_layer(decoder_input_embedding)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m decoder_contexual_embedding=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositional_encoded_input_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m final_output=\u001b[38;5;28mself\u001b[39m.decoder_final_projection(decoder_contexual_embedding)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Transformers-Coding-and-Multi-GPU-Training-from-Scratch\\trans-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Transformers-Coding-and-Multi-GPU-Training-from-Scratch\\trans-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[889]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mdecoder.forward\u001b[39m\u001b[34m(self, x, encoder_output, decoder_mask, encoder_mask)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,encoder_output,decoder_mask,encoder_mask):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dec_blks:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         x=\u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Transformers-Coding-and-Multi-GPU-Training-from-Scratch\\trans-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Transformers-Coding-and-Multi-GPU-Training-from-Scratch\\trans-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: decoderBlock.forward() got an unexpected keyword argument 'decoder_mask'"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884c4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c941049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
